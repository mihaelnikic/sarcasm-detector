{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Method for filtering lexicon L2 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyprind\n",
    "import os\n",
    "\n",
    "def extract_lexicon(doc, sent_emotion, file_length, only_accepted=True):\n",
    "    \"\"\" Extract words with specified sentiment/emotion from a given file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str,\n",
    "        Path to target input file.\n",
    "    \n",
    "    sent_emotion : str, {'positive', 'negative', 'anger', 'fear', 'anticipation', 'trust', 'surprise', 'sadness', 'joy', 'disgust'}\n",
    "          Specifies what kind of words are going to be extracted.\n",
    "    \n",
    "    file_length : int,\n",
    "         Length of the input file.\n",
    "    \n",
    "    only_accepted : boolean,\n",
    "        If 'True' the output will containt only words specified with given sentiment or emotion. Else if 'False', \n",
    "        the output will contain words + 0 or 1 indicator that indicates if specified sentiment/emotion is or isn't fulfilled.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "         Two-dimensional size-mutable, potentially heterogeneous tabular data structure that contains extracted words.\n",
    "    \"\"\"\n",
    "    pbar = pyprind.ProgBar(file_length)\n",
    "    df = pd.DataFrame()\n",
    "    with open(doc, 'r') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip().split('\\t')\n",
    "            if(line[1] == sent_emotion):\n",
    "                if(only_accepted == False):\n",
    "                    df = df.append([[line[0], line[2]]], ignore_index=True)\n",
    "                elif(int(line[2]) == 1):\n",
    "                    df = df.append([line[0]], ignore_index=True)\n",
    "            pbar.update()\n",
    "    df.columns = ['word'] if only_accepted else ['word', 'annotation']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 1. Extracting words from lexicon that are annotated as 'positive' ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:03\n"
     ]
    }
   ],
   "source": [
    "df = extract_lexicon('./original/NRC-emotion-lexicon-wordlevel-alphabetized-v0.92_no_intro.txt', 'positive', only_accepted=True, file_length=141820)\n",
    "df.to_csv('./filtered/l2_lexicon_positive_words.pos', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abovementioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>absorbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>academy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word\n",
       "0            abba\n",
       "1         ability\n",
       "2  abovementioned\n",
       "3        absolute\n",
       "4      absolution\n",
       "5        absorbed\n",
       "6       abundance\n",
       "7        abundant\n",
       "8        academic\n",
       "9         academy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./filtered/l2_lexicon_positive_words.pos', encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 2. Extracting words from lexicon that are annotated as 'negative' ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:03\n"
     ]
    }
   ],
   "source": [
    "df = extract_lexicon('./original/NRC-emotion-lexicon-wordlevel-alphabetized-v0.92_no_intro.txt', 'negative', only_accepted=True, file_length=141820)\n",
    "df.to_csv('./filtered/l2_lexicon_negative_words.neg', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aberration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abhor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abhorrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word\n",
       "0      abandon\n",
       "1    abandoned\n",
       "2  abandonment\n",
       "3    abduction\n",
       "4     aberrant\n",
       "5   aberration\n",
       "6        abhor\n",
       "7    abhorrent\n",
       "8       abject\n",
       "9     abnormal"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./filtered/l2_lexicon_negative_words.neg', encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Formatting lexicon(s) into format which is compatibile with nltk class SentimentIntensityAnalyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = pd.read_csv('./filtered/l2_lexicon_negative_words.neg', encoding='utf-8')\n",
    "neg = pd.read_csv('./filtered/l2_lexicon_positive_words.pos', encoding='utf-8')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# storing positive words with value 1.0\n",
    "for index, row in pos.iterrows():\n",
    "    df = df.append([[row['word'], 1.0]], ignore_index=True)\n",
    "\n",
    "# storing negative words with value -1.0\n",
    "for index, row in neg.iterrows():\n",
    "    df = df.append([[row['word'], -1.0]], ignore_index=True)\n",
    "\n",
    "df.columns = ['word', 'polarity']\n",
    "df.to_csv('./filtered/l2_lexicon_formatted.txt', sep='\\t', header=False, index=False, encoding='utf-8')\n",
    "\n",
    "# remove last '\\n' from a lexicon\n",
    "with open('./filtered/l2_lexicon_formatted.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    last = len(lines) - 1\n",
    "    lines[last] = lines[last].replace('\\r','').replace('\\n','')\n",
    "with open('./filtered/l2_lexicon_formatted.txt', 'w') as wr:\n",
    "    wr.writelines(lines)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
